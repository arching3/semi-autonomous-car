인공지능 자율주행자동차

ESP32 명령 주고받기, 차체 제어
ESP32-Ai 사진데이터 전송
읽어온 영상데이터를 파이썬 서버로 전송, 파이썬에서 디코더해서
OPENCV로 차선검출, 표지판 인식
알고리즘 찾는게 가장 중요한듯


순서도
ESP32가 서버접속 시도.
서버접속에 성공시 명령 수신 대기
시동명령을 수신하면 ESP32 - ESP32-Ai간 시리얼 통신으로 전송시작명령 송신.
ESP32-Ai에서 사진 데이터를 보내옴(스트림에 접속가능해지면서, numpy배열로 읽기 가능)
파이썬 서버에서 수신하여 OPENCV로 디코딩, Canny로 변환
Ctypes 모듈을 이용해서 C언어로 Opencv처리해서 결과값만 반환하든가,
파이썬으로 직접 처리해서 명령을 보내는 방식 둘 중 택1
ESP32는 명령을 받으면 차체를 제어하는 방식
반복. ESP32가 종료명령을 받으면 차체멈춤 & 시리얼 통신으로 ESP32-Ai에게 중단명령 송신




알고리즘 구성

읽어들이는 색공간은 YUV
Y는 밝기, U는 파란색 계통, V는 빨간색 계통

표지판을 뽑아내는 순서는

1) 속도제한표지판
1 - 읽어들인 이미지를 YUV 색공간으로 변환 후,
2 - cv2.split()를 사용해 밝기, 빨간 계통만 뽑아낸다.
3 - 그 다음 cv2.threshold(src,threshold(int),maxval,cv2.THRESH_BINARY_INV)를
이용해서 ret, th로 값 받기 (이진화 과정)
4 - 이진화한 이미지를 cv2.bitwise_not(th)로 반전시켜주고,
cv2.findContours()함수로 contours, hr 받기. (외곽값 뽑아내서 도형 인식)
5 - contours인덱스로 접근해서 cv2.boudingRect()든 뭐든
도형함수로 x,y,w,h 값 뽑아내서 밝기사진에서 roi뽑아내기
6 - roi를 또 다시 cv2.threshold()함수로 이진화하기
7 - 이진화한 roi를 가우시안 블러 적용 후 적응형 threshold로 선명화


2) 방향지시표지판
속도제한표지판과 완전히 동일하나 YUV 색공간에서 Y와 U를 이용하는 것이 특징.
(대부분 파란색이기 때문에)


인식방법
1) 평균 해시 매칭
2) 템플릿 매칭

평균해시 매칭은 템플릿 매칭에 비해 컨튜어 변환에 이진화까지 해야해서
코드가 길어지는 반면에 템플릿 매칭은 코드가 짧음

하지만 정확도 면에선 평균해시 매칭이 더 크다

사실 둘을 적절히 섞을 수 있을 것 같은데, 나중에.



대상 인식은 평균 해시 매칭으로 이용.
이미지의 크기는 64x64로 픽스
image_hash_value.xml에 인식이미지의 해시값 저장돼있음.




카메라 세팅값
SVGA
Brightness 2
Contrast 2
Saturation 2

1. 카메라 구성, 데이터 뽑아오기 //해결
2. 차선검출 및 표지판 인식 알고리즘 구현
3. 몸체 구성 //해결
4. 전원 공급 문제 해결 //해결-보조배터리 사용하여
5. 속도의 상대성 해결//? 해결?
6. 안정성 속도 문제 해결



진행상황
해쉬 매칭으로 roi 매칭할랬는데,
문제가 있는게 아마 내 생각으론 단일채널에서만 적용가능한 것 같다.
따라서
지금 해논 1차 이진화만 적용하고, 적응형 이진화는 빼버리고, 1차 이진화에서 얻어온
roi 좌표값을 원본 src가 살아있으니깐 gray로 변환 후 슬라이싱해서 해쉬에다 적용시켜보고, 비교대상이미지는 코드 첫부분에서 할 것.


해쉬값은 회전과 크기 변화에 약함.
아무래도 모멘트 처리를 해야할 듯.


휴 모멘트 처리를 위해 기존 YUV 공간에서는 표지판 인식만을 위해 사용하고
이후 숫자검출을 위해 HSV 공간으로 변경, V를 활용해 검은색 검출
컨튜어를 찾아 비교하여 휴 모멘트 처리.

성공. 다만 인식률이 50과 70을 헷갈려 하는 경향이 있음.
이는 카메라를 조정하는 등의 연산을 시행해야 할 듯.


차량 검출 알고리즘 개발 시작
대략 카메라의 위치로부터 차체 전방으로 대략 19cm가 카메라가 볼 수 있는 각도 한계

물체가 19cm 안으로 들어와버리면 카메라가 못봄 이 점 유의해서 개발 시작